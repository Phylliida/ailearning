{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul000(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    return torch.matmul(a, b) # also a@b, though @ is actually much more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul00(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    return torch.einsum(\"ik,kj->ij\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul0(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    c = torch.zeros([ah,bw])\n",
    "    for y in range(ah):\n",
    "        c[y] = ((a[y][:,None]*b).sum(axis=0)) # access row, then turn it into a column, then multiply will broadcast it into a repeated column as we want. Now we want to sum along axis=0 since that's vertical, which is the dot product we are doing.\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul1(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    c = torch.zeros([ah,bw])\n",
    "    for y in range(ah):\n",
    "        c[y] = ((a[y]*b.T).sum(axis=1)) # broadcast and multiply by each column (now rows because .T), then sum each row. Axis=1 because we are looping through columsn to do summing, not rows (which is axis=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul2(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    c = torch.zeros([ah,bw])\n",
    "    for y in range(ah):\n",
    "        for x in range(bw):\n",
    "            for k in range(aw):\n",
    "                c[y,x] += a[y,k]*b[k,x]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul3(a, b):\n",
    "    ah, aw = a.shape\n",
    "    bh, bw = b.shape\n",
    "    assert(aw==bh)\n",
    "    c = torch.zeros([ah,bw])\n",
    "    for y in range(ah):\n",
    "        for x in range(bw):\n",
    "            c[y,x] = (a[y]*b[:,x]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4, 4],\n",
      "        [4, 4, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[10,  2,  3],\n",
       "         [-2,  5,  1]]),\n",
       " tensor([[10, 10],\n",
       "         [ 2,  2],\n",
       "         [ 3,  3]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "a = torch.tensor([[10, 2, 3], [-2, 5, 1]])\n",
    "\n",
    "b = torch.tensor([[30, 2], [20, 1], [1, -3]])\n",
    "\n",
    "print(torch.tensor([4]).expand_as(b.T))\n",
    "\n",
    "#b.T, a[0], a[0]*b.T, (a[0]*b.T).sum(axis=1)\n",
    "\n",
    "a, a[0][:,None].expand_as(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7 µs ± 9.09 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "57.8 µs ± 31.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.45 ms ± 762 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Wall time: 3.02 ms\n",
      "Wall time: 15.1 s\n",
      "Wall time: 76.8 ms\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand([100, 200])\n",
    "b = torch.rand([200, 40])\n",
    "%timeit -n 10 t1=matmul000(a,b)\n",
    "%timeit -n 10 t2=matmul00(a,b)\n",
    "%timeit -n 10  t3=matmul0(a,b)\n",
    "%time  t4=matmul1(a,b)\n",
    "%time t5=matmul2(a,b)\n",
    "%time t6=matmul3(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 6],\n",
       "         [1, 4, 6],\n",
       "         [1, 4, 6]]),\n",
       "  1\n",
       "  4\n",
       "  6\n",
       " [torch.LongStorage of size 3],\n",
       " (0, 1),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will expand it, but when you look at storage it only stores it once\n",
    "\n",
    "c = torch.tensor([1, 4, 6])\n",
    "d = torch.tensor([[10, 2, 3], [-2, 5, 1], [3,2,1]])\n",
    "t = c.expand_as(d)\n",
    "t, t.storage(), t.stride(), t.shape\n",
    "# The stride is (0,1) since for columns it moves through the data hopping along 1 each time, but for rows it moves along 0 each time (thus it stays in the same place)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 6]]) torch.Size([1, 3]) tensor([[1],\n",
      "        [4],\n",
      "        [6]]) torch.Size([3, 1])\n",
      "tensor([[[10,  2,  3],\n",
      "         [-2,  5,  1],\n",
      "         [ 3,  2,  1]]]) torch.Size([1, 3, 3]) tensor([[[10,  2,  3]],\n",
      "\n",
      "        [[-2,  5,  1]],\n",
      "\n",
      "        [[ 3,  2,  1]]]) torch.Size([3, 1, 3]) tensor([[[10],\n",
      "         [ 2],\n",
      "         [ 3]],\n",
      "\n",
      "        [[-2],\n",
      "         [ 5],\n",
      "         [ 1]],\n",
      "\n",
      "        [[ 3],\n",
      "         [ 2],\n",
      "         [ 1]]]) torch.Size([3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze adds a length 1 dimension at the desired spot\n",
    "c = torch.tensor([1, 4, 6])\n",
    "c.unsqueeze(0), c.unsqueeze(0).shape, c.unsqueeze(1), c.unsqueeze(1).shape\n",
    "d = torch.tensor([[10, 2, 3], [-2, 5, 1], [3,2,1]])\n",
    "d.unsqueeze(0), d.unsqueeze(0).shape, d.unsqueeze(1), d.unsqueeze(1).shape, d.unsqueeze(2), d.unsqueeze(2).shape\n",
    "# Shorthand notation:\n",
    "print(c[None], c[None].shape, c[:,None], c[:,None].shape)\n",
    "print(d[None], d[None].shape, d[:,None], d[:,None].shape, d[:,:,None], d[:,:,None].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.tensor([[10, 2, 3], [-2, 5, 1], [3,2,1]])\n",
    "# ... anywhere means that after it you are working from the last axis backwards, instead of the first axis forwards.\n",
    "d[0,...,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general rule is that they start from the last axis and work backwards. Each axis is compatible if:\n",
    "\n",
    "1. They are the same size\n",
    "2. One of them is 1, in which case it is broadcasted to be the same size as the other axis\n",
    "\n",
    "If one thing has less axis, it still starts from the last axis of both things and works backwards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros([3,10,4])\n",
    "\n",
    "a*(torch.zeros([3])[:,None,None])\n",
    "a*(torch.zeros([10])[:,None])\n",
    "a*(torch.zeros([4]))\n",
    "a*torch.zeros([3,1,1])\n",
    "a*torch.zeros([1,10,1])\n",
    "a*torch.zeros([1,1,4])\n",
    "a*torch.zeros([3,1,4])\n",
    "a*torch.zeros([1,10,4])\n",
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[343,  13],\n",
      "        [ 41,  -2]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.tensor([[10, 2, 3], [-2, 5, 1]])\n",
    "\n",
    "b = torch.tensor([[30, 2], [20, 1], [1, -3]])\n",
    "\n",
    "print(torch.einsum(\"ik,kj->ij\", a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2952, -0.9341, -0.4223, -1.0190,  0.2456, -0.6133, -1.4080, -1.3623,\n",
       "          0.4348,  0.2256],\n",
       "        [ 0.5693, -0.2497,  0.9739,  0.2206,  1.3143,  1.3304,  1.0459,  0.0500,\n",
       "          1.0873,  0.6846],\n",
       "        [-0.1863, -0.3399, -1.2109, -1.9753,  0.5485, -2.0030, -1.3316,  0.2011,\n",
       "         -0.6782, -0.5050],\n",
       "        [ 0.7071, -0.8895,  0.7457, -0.2768, -1.1438, -2.4894, -0.5299, -0.4752,\n",
       "          2.3249,  1.3471],\n",
       "        [ 0.1760, -2.4201, -1.1801,  1.0719, -2.3071,  2.1724,  0.0092, -0.2826,\n",
       "         -0.4482,  1.8626],\n",
       "        [-0.7799,  0.9627,  1.3358,  0.3358,  0.0445, -0.4429, -1.4348, -1.5696,\n",
       "          0.5019,  0.7517],\n",
       "        [-0.3472,  0.2741,  0.0111,  1.3033, -0.6587,  0.5325, -0.0851,  0.6103,\n",
       "         -1.6681,  1.7016],\n",
       "        [-1.2076, -1.3069, -0.2687,  0.2841, -1.6222,  1.4335, -0.5556, -1.1500,\n",
       "         -0.1205,  1.2446],\n",
       "        [-0.8119,  0.8948, -0.8631,  0.0553,  0.4175, -0.8051, -0.4708,  0.5994,\n",
       "         -0.5824, -0.1118],\n",
       "        [ 0.1029, -0.8275, -0.4112,  0.4238,  2.2661, -2.1956, -1.3877, -1.7371,\n",
       "          0.0045,  1.4685]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = torch.normal(0.0, 1.0, [1000, 720])\n",
    "data_y = torch.randint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros([10, 20, 3]).numel() # numel multiplies all the dimensions together, useful for finding size of input or output\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
