{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.nn import functional as F\n",
    "from minGPT.mingpt import model\n",
    "# make deterministic\n",
    "from minGPT.mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automataBattle\n",
    "from importlib import reload\n",
    "reload(automataBattle)\n",
    "from torch.utils.data import Dataset\n",
    "class FastLearnAutomataDataset(Dataset):\n",
    "    def __init__(self, nStates, nSymbols, split, sequenceLen, numSequences):\n",
    "        self.nStates = nStates\n",
    "        self.nSymbols = nSymbols\n",
    "        self.split = split # train/test\n",
    "        self.vocab_size = nSymbols*nSymbols\n",
    "        # +1 due to potential carry overflow, but then -1 because very last digit doesn't plug back\n",
    "        self.block_size = sequenceLen\n",
    "        \n",
    "        self.sequenceLen, self.numSequences = sequenceLen, numSequences\n",
    "        \n",
    "        '''\n",
    "        # split up all addition problems into either training data or test data\n",
    "        num = (10**self.ndigit)**2 # total number of possible combinations\n",
    "        r = np.random.RandomState(1337) # make deterministic\n",
    "        perm = r.permutation(num)\n",
    "        num_test = min(int(num*0.2), 1000) # 20% of the whole dataset, or only up to 1000\n",
    "        self.ixes = perm[:num_test] if split == 'test' else perm[num_test:]\n",
    "        '''\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.numSequences\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        a = automataBattle.Automata(nStates=self.nStates, symbols=range(self.nSymbols), randomConnect=True)\n",
    "        a.minimize()\n",
    "        while a.complexity() != self.nStates:\n",
    "            a = automataBattle.Automata(nStates=self.nStates, symbols=range(self.nSymbols), randomConnect=True)\n",
    "            a.minimize()\n",
    "        X, Y = a.generate(self.sequenceLen, lambda: random.choice(range(self.nSymbols)))\n",
    "        x = torch.tensor(X)\n",
    "        y = torch.tensor(Y) # predict the output of the Automata\n",
    "        previous = y[:-1]\n",
    "        shiftedForwadInputsOne = x[1:]\n",
    "        outputs = y[1:] # Todo: look into encoding multiple things (\"tuple encodings\") instead of this gross thing\n",
    "        xOutput = shiftedForwadInputsOne+previous*self.nSymbols\n",
    "        yOutput = outputs\n",
    "        return xOutput, yOutput\n",
    "        \n",
    "        '''\n",
    "        # given a problem index idx, first recover the associated a + b\n",
    "        idx = self.ixes[idx]\n",
    "        nd = 10**self.ndigit\n",
    "        a = idx // nd\n",
    "        b = idx %  nd\n",
    "        c = a + b\n",
    "        render = f'%0{self.ndigit}d%0{self.ndigit}d%0{self.ndigit+1}d' % (a,b,c) # e.g. 03+25=28 becomes \"0325028\" \n",
    "        dix = [int(s) for s in render] # convert each character to its token index\n",
    "        # x will be input to GPT and y will be the associated expected outputs\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long) # predict the next token in the sequence\n",
    "        y[:self.ndigit*2-1] = -100 # we will only train in the output locations. -100 will mask loss to zero\n",
    "        return x, y\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/20/2020 21:52:47 - INFO - minGPT.mingpt.model -   number of parameters: 4.069120e+05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3, 2, 2, 2, 1, 2, 3, 3, 2, 3, 3, 3, 1, 0, 1, 2, 3, 2, 3, 3, 2, 0, 2, 0,\n",
      "        3, 0, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 3, 1, 0, 0, 3, 0, 1, 2, 2, 2, 3,\n",
      "        0, 1, 2, 2, 3, 3, 3, 0, 0, 3, 0, 0, 2, 1, 2, 3, 3, 2, 3, 2, 2, 2, 2, 1,\n",
      "        2, 2, 3, 3, 2, 0, 3, 1, 0, 1, 2, 3, 3, 2, 3, 3, 2, 0, 3, 0, 0, 2, 1, 2,\n",
      "        2, 3, 3]), tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1])) (tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3,\n",
      "        3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2,\n",
      "        3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2,\n",
      "        2, 3, 3]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import minGPT\n",
    "from importlib import reload\n",
    "from minGPT.mingpt import trainer\n",
    "from minGPT.mingpt import model\n",
    "reload(minGPT.mingpt.model)\n",
    "reload(minGPT.mingpt.trainer)\n",
    "from minGPT.mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "import gc\n",
    "model = None\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "train_dataset = FastLearnAutomataDataset(nStates=4, nSymbols=2, split='train', sequenceLen=100, numSequences=6000000)\n",
    "test_dataset = FastLearnAutomataDataset(nStates=4, nSymbols=2, split='test', sequenceLen=100, numSequences=2000)\n",
    "print(train_dataset[0], train_dataset[1])\n",
    "# initialize a baby GPT model\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, \n",
    "                  n_layer=8, n_head=8, n_embd=64)\n",
    "model = GPT(mconf)\n",
    "model.load_state_dict(torch.load(\"juniper_fit_actual_4_states\"))\n",
    "from minGPT.mingpt.trainer import Trainer, TrainerConfig\n",
    "set_seed(27)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 145: train loss 0.14818. lr 5.998999e-05:   1%|          | 146/11719 [00:23<30:48,  6.26it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 156: train loss 0.14982. lr 5.998843e-05:   1%|▏         | 157/11719 [00:25<30:27,  6.33it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 161: train loss 0.15417. lr 5.998768e-05:   1%|▏         | 162/11719 [00:26<30:36,  6.29it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 162: train loss 0.14729. lr 5.998753e-05:   1%|▏         | 163/11719 [00:26<30:40,  6.28it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 1 iter 163: train loss 0.15132. lr 5.998737e-05:   1%|▏         | 164/11719 [00:26<30:56,  6.23it/s]w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 164: train loss 0.15081. lr 5.998722e-05:   1%|▏         | 165/11719 [00:27<30:54,  6.23it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 165: train loss 0.14919. lr 5.998706e-05:   1%|▏         | 166/11719 [00:27<31:08,  6.18it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 166: train loss 0.15224. lr 5.998691e-05:   1%|▏         | 167/11719 [00:27<31:01,  6.21it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 1 iter 167: train loss 0.15041. lr 5.998675e-05:   1%|▏         | 168/11719 [00:27<31:11,  6.17it/s]w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 168: train loss 0.14928. lr 5.998659e-05:   1%|▏         | 169/11719 [00:27<31:03,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 169: train loss 0.15036. lr 5.998643e-05:   1%|▏         | 170/11719 [00:27<31:13,  6.16it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "epoch 1 iter 170: train loss 0.15283. lr 5.998627e-05:   1%|▏         | 171/11719 [00:27<31:20,  6.14it/s]can only join a child process\n",
      "epoch 1 iter 172: train loss 0.14953. lr 5.998595e-05:   1%|▏         | 173/11719 [00:28<31:04,  6.19it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 173: train loss 0.15154. lr 5.998579e-05:   1%|▏         | 174/11719 [00:28<30:57,  6.22it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 1 iter 174: train loss 0.14900. lr 5.998562e-05:   1%|▏         | 175/11719 [00:28<31:02,  6.20it/s]    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 1 iter 175: train loss 0.15032. lr 5.998546e-05:   2%|▏         | 176/11719 [00:28<31:07,  6.18it/s]    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 1 iter 11718: train loss 0.14247. lr 1.554741e-05: 100%|██████████| 11719/11719 [31:01<00:00,  6.30it/s]\n",
      "10/20/2020 22:24:02 - INFO - minGPT.mingpt.trainer -   test loss: 0.134985\n",
      "epoch 2 iter 129: train loss 0.14548. lr 1.494659e-05:   1%|          | 130/11719 [00:21<30:36,  6.31it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "epoch 2 iter 130: train loss 0.14088. lr 1.494200e-05:   1%|          | 131/11719 [00:21<30:49,  6.27it/s]\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 131: train loss 0.14028. lr 1.493741e-05:   1%|          | 132/11719 [00:21<30:48,  6.27it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 2 iter 132: train loss 0.14412. lr 1.493282e-05:   1%|          | 132/11719 [00:21<30:48,  6.27it/s]\n",
      "epoch 2 iter 132: train loss 0.14412. lr 1.493282e-05:   1%|          | 133/11719 [00:21<30:58,  6.23it/s]  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 133: train loss 0.14414. lr 1.492823e-05:   1%|          | 134/11719 [00:21<30:56,  6.24it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 136: train loss 0.14057. lr 1.491446e-05:   1%|          | 137/11719 [00:22<30:40,  6.29it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "epoch 2 iter 137: train loss 0.14304. lr 1.490987e-05:   1%|          | 138/11719 [00:22<30:49,  6.26it/s]  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 2 iter 138: train loss 0.14609. lr 1.490529e-05:   1%|          | 139/11719 [00:22<31:01,  6.22it/s]    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 141: train loss 0.14413. lr 1.489153e-05:   1%|          | 142/11719 [00:23<31:01,  6.22it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 143: train loss 0.14325. lr 1.488236e-05:   1%|          | 144/11719 [00:23<30:55,  6.24it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 144: train loss 0.14406. lr 1.487777e-05:   1%|          | 145/11719 [00:23<31:08,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 146: train loss 0.14230. lr 1.486860e-05:   1%|▏         | 147/11719 [00:23<31:06,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 149: train loss 0.14411. lr 1.485486e-05:   1%|▏         | 150/11719 [00:24<31:08,  6.19it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "epoch 2 iter 150: train loss 0.14312. lr 1.485028e-05:   1%|▏         | 151/11719 [00:24<31:14,  6.17it/s]self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "epoch 2 iter 151: train loss 0.14336. lr 1.484569e-05:   1%|▏         | 152/11719 [00:24<31:44,  6.07it/s]AssertionError: can only join a child process\n",
      "epoch 2 iter 155: train loss 0.14164. lr 1.482737e-05:   1%|▏         | 156/11719 [00:25<31:00,  6.21it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 157: train loss 0.14326. lr 1.481822e-05:   1%|▏         | 158/11719 [00:25<30:51,  6.24it/s]Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 158: train loss 0.14109. lr 1.481364e-05:   1%|▏         | 159/11719 [00:25<31:10,  6.18it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 2 iter 159: train loss 0.14498. lr 1.480906e-05:   1%|▏         | 160/11719 [00:26<31:10,  6.18it/s]    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 2 iter 11718: train loss 0.14580. lr 1.392521e-05: 100%|██████████| 11719/11719 [31:01<00:00,  6.30it/s]\n",
      "10/20/2020 22:55:05 - INFO - minGPT.mingpt.trainer -   test loss: 0.134878\n",
      "epoch 3 iter 131: train loss 0.14700. lr 1.452113e-05:   1%|          | 132/11719 [00:21<30:33,  6.32it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 132: train loss 0.14338. lr 1.452568e-05:   1%|          | 133/11719 [00:21<30:37,  6.31it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "\n",
      "epoch 3 iter 133: train loss 0.14339. lr 1.453022e-05:   1%|          | 133/11719 [00:22<30:37,  6.31it/s]w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "epoch 3 iter 133: train loss 0.14339. lr 1.453022e-05:   1%|          | 134/11719 [00:22<30:49,  6.26it/s]  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'AssertionError: can only join a child process\n",
      "epoch 3 iter 136: train loss 0.14276. lr 1.454387e-05:   1%|          | 137/11719 [00:22<31:04,  6.21it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 137: train loss 0.14409. lr 1.454842e-05:   1%|          | 138/11719 [00:22<31:15,  6.18it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 138: train loss 0.14295. lr 1.455297e-05:   1%|          | 139/11719 [00:22<31:19,  6.16it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 139: train loss 0.14121. lr 1.455752e-05:   1%|          | 140/11719 [00:23<31:07,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "epoch 3 iter 140: train loss 0.14357. lr 1.456207e-05:   1%|          | 141/11719 [00:23<31:13,  6.18it/s]AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "epoch 3 iter 141: train loss 0.14346. lr 1.456662e-05:   1%|          | 142/11719 [00:23<31:52,  6.05it/s]  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 142: train loss 0.14247. lr 1.457117e-05:   1%|          | 143/11719 [00:23<31:30,  6.12it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 143: train loss 0.14308. lr 1.457573e-05:   1%|          | 144/11719 [00:23<31:19,  6.16it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 144: train loss 0.14360. lr 1.458028e-05:   1%|          | 145/11719 [00:23<31:31,  6.12it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 145: train loss 0.14518. lr 1.458483e-05:   1%|          | 146/11719 [00:23<31:17,  6.16it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 146: train loss 0.14440. lr 1.458939e-05:   1%|▏         | 147/11719 [00:24<31:07,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "epoch 3 iter 147: train loss 0.14140. lr 1.459394e-05:   1%|▏         | 148/11719 [00:24<31:13,  6.18it/s]w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 148: train loss 0.14254. lr 1.459850e-05:   1%|▏         | 149/11719 [00:24<31:06,  6.20it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 150: train loss 0.14429. lr 1.460761e-05:   1%|▏         | 151/11719 [00:24<31:23,  6.14it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 153: train loss 0.13985. lr 1.462128e-05:   1%|▏         | 154/11719 [00:25<31:26,  6.13it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ba4b45e50>\n",
      "Traceback (most recent call last):\n",
      "epoch 3 iter 154: train loss 0.14240. lr 1.462584e-05:   1%|▏         | 154/11719 [00:25<31:26,  6.13it/s]  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "epoch 3 iter 154: train loss 0.14240. lr 1.462584e-05:   1%|▏         | 155/11719 [00:25<31:16,  6.16it/s]    self._shutdown_workers()\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/phylliida/miniconda3/envs/sandbox1/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "epoch 3 iter 2655: train loss 0.14411. lr 2.713793e-05:  23%|██▎       | 2656/11719 [07:02<24:22,  6.20it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=100, batch_size=512, learning_rate=6e-5,\n",
    "                      lr_decay=True, warmup_tokens=512, final_tokens=50*len(train_dataset)*(2+1),\n",
    "                      num_workers=16)\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"juniper_fit_actual_4_states_2\"\n",
    "raw_model = model.module if hasattr(model, \"module\") else model\n",
    "torch.save(raw_model.state_dict(), ckpt_path)\n",
    "\n",
    "# seems 8layer, 8head, embed32 got stuck at around 0.5, but it's possible it could have gone further\n",
    "# juniper_fit fit really well, n_layer=8, n_head=8, n_embd=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "not pre-fit to 2, n_layer=8, n_head=8, n_embd=64\n",
    "epoch 1 iter 2343: train loss 0.49225. lr 1.445926e-05: 100%|██████████| 2344/2344 [13:45<00:00,  2.84it/s]\n",
    "10/20/2020 13:35:34 - INFO - minGPT.mingpt.trainer -   test loss: 0.498138\n",
    "epoch 2 iter 2343: train loss 0.49982. lr 1.610073e-05: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 13:49:17 - INFO - minGPT.mingpt.trainer -   test loss: 0.473743\n",
    "epoch 3 iter 2343: train loss 0.47190. lr 5.994085e-05: 100%|██████████| 2344/2344 [13:41<00:00,  2.85it/s]\n",
    "10/20/2020 14:02:58 - INFO - minGPT.mingpt.trainer -   test loss: 0.592071\n",
    "epoch 4 iter 2343: train loss 0.49541. lr 1.287954e-05: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 14:16:41 - INFO - minGPT.mingpt.trainer -   test loss: 0.498718\n",
    "epoch 5 iter 2343: train loss 0.47400. lr 1.779652e-05: 100%|██████████| 2344/2344 [13:40<00:00,  2.86it/s]\n",
    "10/20/2020 14:30:22 - INFO - minGPT.mingpt.trainer -   test loss: 0.514086\n",
    "epoch 6 iter 2343: train loss 0.47976. lr 5.976367e-05: 100%|██████████| 2344/2344 [13:41<00:00,  2.85it/s]\n",
    "10/20/2020 14:44:03 - INFO - minGPT.mingpt.trainer -   test loss: 0.396569\n",
    "epoch 7 iter 2343: train loss 0.48898. lr 1.136731e-05: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 14:57:45 - INFO - minGPT.mingpt.trainer -   test loss: 0.506740\n",
    "epoch 8 iter 2343: train loss 0.47964. lr 1.954042e-05: 100%|██████████| 2344/2344 [13:44<00:00,  2.84it/s]\n",
    "10/20/2020 15:11:30 - INFO - minGPT.mingpt.trainer -   test loss: 0.464614\n",
    "epoch 9 iter 2343: train loss 0.47039. lr 5.946917e-05: 100%|██████████| 2344/2344 [13:40<00:00,  2.86it/s]\n",
    "10/20/2020 15:25:11 - INFO - minGPT.mingpt.trainer -   test loss: 0.503165\n",
    "epoch 10 iter 2343: train loss 0.46504. lr 9.928526e-06: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 15:38:54 - INFO - minGPT.mingpt.trainer -   test loss: 0.479228\n",
    "epoch 11 iter 2343: train loss 0.46503. lr 2.132556e-05: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 15:52:37 - INFO - minGPT.mingpt.trainer -   test loss: 0.493589\n",
    "epoch 12 iter 2343: train loss 0.44574. lr 5.905849e-05: 100%|██████████| 2344/2344 [13:43<00:00,  2.85it/s]\n",
    "10/20/2020 16:06:20 - INFO - minGPT.mingpt.trainer -   test loss: 0.436838\n",
    "epoch 13 iter 2343: train loss 0.44981. lr 8.568867e-06: 100%|██████████| 2344/2344 [13:41<00:00,  2.85it/s]\n",
    "10/20/2020 16:20:01 - INFO - minGPT.mingpt.trainer -   test loss: 0.445516\n",
    "epoch 14 iter 2343: train loss 0.44436. lr 2.314489e-05: 100%|██████████| 2344/2344 [13:40<00:00,  2.86it/s]\n",
    "10/20/2020 16:33:42 - INFO - minGPT.mingpt.trainer -   test loss: 0.409083\n",
    "epoch 15 iter 2343: train loss 0.45118. lr 5.853326e-05: 100%|██████████| 2344/2344 [13:41<00:00,  2.85it/s]\n",
    "10/20/2020 16:47:24 - INFO - minGPT.mingpt.trainer -   test loss: 0.320424\n",
    "epoch 16 iter 2343: train loss 0.44524. lr 7.293692e-06: 100%|██████████| 2344/2344 [13:41<00:00,  2.85it/s]\n",
    "10/20/2020 17:01:05 - INFO - minGPT.mingpt.trainer -   test loss: 0.412357\n",
    "epoch 17 iter 2343: train loss 0.44509. lr 2.499124e-05: 100%|██████████| 2344/2344 [13:42<00:00,  2.85it/s]\n",
    "10/20/2020 17:14:48 - INFO - minGPT.mingpt.trainer -   test loss: 0.498460\n",
    "epoch 18 iter 656: train loss 0.43165. lr 6.000000e-06:  28%|██▊       | 657/2344 [03:50<09:52,  2.85it/s]\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
