{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So it seems like a good idea would be something that can take two gradients and turn them into one gradient\n",
    "# That one gradient could be better than just averaging by minimizing a loss that computes the smallest decrease\n",
    "#  in loss over the data. The idea is to bootstrap and make the data more useful than it would have otherwise been,\n",
    "#  as a form of regularization where we are forcing generalization in our gradient steps\n",
    "\n",
    "# There is next a question of if we can convert this distilled gradient back into a piece of data.\n",
    "# One way to do this is simply by running gradient descent for multiple steps, then computing the total change in weights\n",
    "# over those steps. That is the \"effective gradient\" of all of those data pieces, and we can distill a single data piece\n",
    "# that obtains that same gradient (just gradient descent the data itself)\n",
    "\n",
    "# However, this only works if you have the same initialization and network. What if this procedure is ran multiple times\n",
    "# on different sizes of networks, and different\n",
    "\n",
    "# Alternatively, what if we make a model that tries to predict the \"next gradient\", given the current one? Or what if, given\n",
    "#  data, it tries to output the data that distills it? If we have two pieces of data, and it outputs one piece of data, we\n",
    "#  could train a \"distillation network\" on lots of different initializations, all at varying levels of being trained, and\n",
    "#  may get a decent model at \"distilling\" two pieces of data into one. This model can be used to divide the size of data in\n",
    "#  half, then in half again, etc., allowing for a very distilled dataset that can rapidly train new models.\n",
    "\n",
    "# It's worth asking how that is any better than just training the model itself. You will still need to run a model on every\n",
    "#   piece of data. You also just have a new hyperparam which might be annoying The improvements would be:\n",
    "# 1. The distillation network might be smaller, because the function to distill is simpler\n",
    "# 2. This allows you to distill once, then experiment more rapidly with many different hyperparams because training is quicker\n",
    "# 3. This makes training more accessible as you don't need to download massive datasets\n",
    "\n",
    "# The questions we would ask about this distiller are:\n",
    "# 1. How well does it generalize to different kinds of networks?\n",
    "# 2. Does it need samples from different amounts of trained networks? (initially trained, trained a little, fully trained)\n",
    "#    to what extent does this influence it's effectiveness?\n",
    "# 3. What are ways of measuring distillation quality? One would be average loss of fitted models on data before distill and after distill\n",
    "# 4. Are there general sorts of tradeoffs we make here? What are they? How do different types of data effect how well this works?\n",
    "# 5. Can this act as data augmentation? Pick two random images and generate a distilled image\n",
    "# 6. How do classification tasks fit into this? Should we only distill images from the same class? Or can we incorporate loss to do it from multiple classes?\n",
    "# 7. We can sort of \"bootstrap\" it, by producing an image, then \"gradient descenting\" that image on trying to maximize the \n",
    "#    smallest increase in loss between the two images to improve it. We can then take this gradient descented image and use\n",
    "#    it to futher train the model.\n",
    "\n",
    "# Can we do that \"gradient bootstrapping\" for standard training as well? Yes:\n",
    "# 1. Take a minibatch\n",
    "# 2. Gradient descent to find the data the maximizes the minimum improvement in loss over that minibatch\n",
    "# 3. Use the gradient of that data instead of the averaged gradient\n",
    "\n",
    "# Even better, what if we train a model to update the weights to improve the loss, and then gradient descent on that\n",
    "# meta model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
