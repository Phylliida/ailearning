{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "def approx_equals(a, b):\n",
    "    assert torch.allclose(a, b, 0.0001), str(a) + \"!=\" + str(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HelpfulModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._myHyperParams = {}\n",
    "        \n",
    "    def __setattr__(self, attr, val):\n",
    "        super().__setattr__(attr, val) # make sure to call super because torch.nn.Module also overrides this\n",
    "        simpleTypes = [int, str, float]\n",
    "        if type(val) in simpleTypes or (type(val) is list and (len(val) == 0 or type(val[0]) in simpleTypes)):\n",
    "            self._myHyperParams[attr] = val\n",
    "            \n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return \", \".join([(str(param) + \": \" + str(val)) for param, val in self._myHyperParams.items()])\n",
    "\n",
    "    \n",
    "def debiasLerp(a, b, p, nBatches):\n",
    "    return torch.lerp(a, b/torch.tensor(p).pow(nBatches), p)\n",
    "    \n",
    "class BatchNorm(HelpfulModule):\n",
    "    def __init__(self, inputSize, mom=0.1, eps=0.01):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.inputSize = inputSize\n",
    "        self.multiplicitiveWeight = nn.Parameter(torch.ones([inputSize]))\n",
    "        self.additiveWeight = nn.Parameter(torch.zeros([inputSize]))\n",
    "        self.register_buffer('running_mean', torch.zeros(inputSize))\n",
    "        self.register_buffer('running_sum_of_squares', torch.zeros(inputSize))\n",
    "        self.register_buffer('running_squared_sum', torch.zeros(inputSize))\n",
    "        self.nBatches = 1\n",
    "    \n",
    "    def resetParams(self):\n",
    "        self.running_mean.zero_()\n",
    "        self.running_sum_of_squares.zero_()\n",
    "        self.running_squared_sum.zero_()\n",
    "        self.nBatches = 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.nBatches += 1\n",
    "        self.running_mean = debiasLerp(self.running_mean, x.mean(axis=0), self.mom, self.nBatches)\n",
    "        self.running_mean_of_squares = debiasLerp(self.running_mean, x.pow(2).mean(axis=0), self.mom, self.nBatches)\n",
    "        self.running_squared_mean = debiasLerp(self.running_mean, x.mean(axis=0).pow(2), self.mom, self.nBatches)\n",
    "        mu = self.running_mean\n",
    "        var = torch.max(self.running_mean_of_squares - self.running_squared_mean, torch.tensor(self.eps))\n",
    "        normalizedOutput = (x-mu)/var\n",
    "        return normalizedOutput*self.multiplicitiveWeight+self.additiveWeight\n",
    "\n",
    "class LayerNorm(HelpfulModule):\n",
    "    def __init__(self, inputSize, mom=0.1, eps=0.01):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.inputSize = inputSize\n",
    "        self.multiplicitiveWeight = nn.Parameter(torch.ones(inputSize))\n",
    "        self.additiveWeight = nn.Parameter(torch.zeros(inputSize))\n",
    "        self.register_buffer('running_mean', torch.tensor(0.0))\n",
    "        self.register_buffer('running_sum_of_squares', torch.tensor(0.0))\n",
    "        self.register_buffer('running_squared_sum', torch.tensor(0.0))\n",
    "        self.nBatches = 0\n",
    "    \n",
    "    def resetParams(self):\n",
    "        self.running_mean.zero_()\n",
    "        self.running_sum_of_squares.zero_()\n",
    "        self.running_squared_sum.zero_()\n",
    "        self.nBatches = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.nBatches += 1\n",
    "        self.running_mean = debiasLerp(self.running_mean, x.mean(), self.mom, self.nBatches)\n",
    "        self.running_mean_of_squares = debiasLerp(self.running_mean, x.pow(2).mean(), self.mom, self.nBatches)\n",
    "        self.running_squared_mean = debiasLerp(self.running_mean, x.mean().pow(2), self.mom, self.nBatches)\n",
    "        mu = self.running_mean\n",
    "        var = torch.max(self.running_mean_of_squares - self.running_squared_mean, torch.tensor(self.eps))\n",
    "        normalizedOutput = (x-mu)/var\n",
    "        return normalizedOutput*self.multiplicitiveWeight+self.additiveWeight\n",
    "\n",
    "\n",
    "        \n",
    "class TransformerBlock(HelpfulModule):\n",
    "    def __init__(self, n, d, k):\n",
    "        super().__init__()\n",
    "        self.n, self.d, self.k = n,d,k\n",
    "        self.Q = nn.Parameter(torch.normal(0, 1, [k, d]))\n",
    "        self.K = nn.Parameter(torch.normal(0, 1, [k, d]))\n",
    "        self.V = nn.Parameter(torch.normal(0, 1, [k, d]))\n",
    "        self.Wch = nn.Parameter(torch.normal(0, 1, [d,k]))\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "    def forward(self, x):\n",
    "        # x is [b,n,d]\n",
    "        # Q, K, and V are [k,d]\n",
    "        # Q*x[i] is [k,d]*[d] = [k]\n",
    "        # so Q*x should be of size [k,d]*[b,n,d] -> [b,n,k]\n",
    "        qh = torch.einsum(\"kd,bnd->bnk\", self.Q, x) # You can test this works by doing Q@x[0,0] and seeing first row is the same row of outputs\n",
    "        kh = torch.einsum(\"kd,bnd->bnk\", self.K, x)\n",
    "        vh = torch.einsum(\"kd,bnd->bnk\", self.V, x)\n",
    "        \n",
    "        # q[i,j] is a vector of size k\n",
    "        # k[i,j] is a vector of size k\n",
    "        # for every pair of (vector from q, vector from k), we need to get an output by taking their dot product\n",
    "        # normally if you have two matrices A and B of size NxM and MxK,\n",
    "        # when you multiply them, you can think of the output matrix's value in the (i,j)th position as the ith row in A dot jth column in B\n",
    "        # (thus it is every pair of row from first and column from second)\n",
    "        # in einsum, torch.einsum(\"ij,jk->ik\", A, B)\n",
    "        # If instead A and B are of size NxM and NxM and you want to do every pair of rows, you can just do\n",
    "        # torch.einsum(\"ij,kj->ik\") # transpose second matrices indices so it takes rows instead of columns\n",
    "        # we have an additional batch index at the front, so include that\n",
    "        dotQueryKey = torch.einsum(\"bij, bkj->bik\", q, k)/math.sqrt(k)\n",
    "        # now the [b,i,j]th element of dotQueryKey is the dot product of q[b,i] and k[b,j].\n",
    "        # since q and k were of dimension [b,n,k], this becomes [b,n,n]\n",
    "        \n",
    "        # If we look at dotQueryKey[b,i], that is a vector of size n.\n",
    "        # the jth term is the ith query dot the jth key vector.\n",
    "        # thus, each term is \"how much\" the ith query aligns with the jth key.\n",
    "        # so we will take a softmax so we actually get probabilities (TODO: try sigmoid. Seems odd that it's only one class of things)\n",
    "        # This doesn't change the dim, so it's still [b,n,n]\n",
    "        queryPrs = self.softmax(dotQueryKey)\n",
    "        \n",
    "        # Now we take sum over i of (queryPrs[b,i,j])*(vh[b,j])\n",
    "        #                            scalar            vector\n",
    "        \n",
    "        \n",
    "        # Now we need to take queryP\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qprs tensor([[[ 1.7650,  0.0664,  0.0753],\n",
      "         [-1.3867,  0.0756, -0.4957],\n",
      "         [-0.8165, -0.0069, -1.7975]],\n",
      "\n",
      "        [[-0.3770, -1.6994,  1.0734],\n",
      "         [-0.1926,  0.5088,  1.2001],\n",
      "         [ 1.0033,  0.3197, -0.6699]]])\n",
      "vh tensor([[[ 0.4601,  0.3644, -1.4775,  0.4753, -0.3383],\n",
      "         [-0.5367,  1.5008, -0.7286,  0.4594,  0.4356],\n",
      "         [-0.2073, -1.0252, -1.1372,  1.0307,  0.4656]],\n",
      "\n",
      "        [[-0.8964,  0.5814, -0.9950, -0.9881, -0.1613],\n",
      "         [ 0.1007,  0.9505,  0.9992, -0.8928,  1.6873],\n",
      "         [ 0.4901,  0.2179,  0.0329,  0.0506, -0.0541]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension mismatch for operand 1: equation 2 tensor 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-393fd49a51dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtestTransformer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-109-393fd49a51dc>\u001b[0m in \u001b[0;36mtestTransformer2\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Now we take sum over i of (queryPrs[b,i,j])*(vh[b,j])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#                            scalar            vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bij,bj->bj\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueryPrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sandbox1/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension mismatch for operand 1: equation 2 tensor 3"
     ]
    }
   ],
   "source": [
    "def testTransformer2():\n",
    "    b, n, d, k = 2, 3, 4, 5\n",
    "    from minGPT.mingpt.utils import set_seed\n",
    "    set_seed(27)\n",
    "    queryPrs = torch.normal(0, 1, [b,n,n])\n",
    "    vh = torch.normal(0, 1, [b,n,k])\n",
    "    print(\"qprs\", queryPrs)\n",
    "    print(\"vh\", vh)\n",
    "    # Now we take sum over i of (queryPrs[b,i,j])*(vh[b,j])\n",
    "    #                            scalar            vector\n",
    "    res = torch.einsum(\"bij,bjw->bjw\", queryPrs, vh)\n",
    "    val = 0.0\n",
    "    bv = 0\n",
    "    jv = 0\n",
    "    for i in range(n):\n",
    "        val += queryPrs[bv,i,jv]*vh[bv,jv]\n",
    "    print(\"ayy\", val)\n",
    "    print(\"res\", res)\n",
    "    \n",
    "    \n",
    "    a = torch.normal(0, 1, [2, 3])\n",
    "    b = torch.normal(0, 1, [2, 3, 4])\n",
    "    \n",
    "testTransformer2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 1.7650,  0.0664, -0.0706, -0.1672],\n",
      "         [-0.4266,  1.5005, -0.2636, -1.0210],\n",
      "         [-1.7975, -0.3770,  0.6140,  0.5948]],\n",
      "\n",
      "        [[-0.8629, -0.9511, -0.9195, -0.7592],\n",
      "         [ 0.3197, -0.6699,  1.5661,  0.8074],\n",
      "         [-1.6036,  0.1696, -0.0308,  0.0434]]])\n",
      "Q: tensor([[ 1.5008, -0.7286, -0.5098,  0.4431],\n",
      "        [-0.9389,  1.5772,  1.6559, -0.4713],\n",
      "        [ 0.4656, -0.8964,  0.5814, -0.9950],\n",
      "        [ 0.6763,  0.1337,  0.0659,  0.5385],\n",
      "        [ 0.9992, -0.8928,  1.6873,  0.4901]])\n",
      "q: tensor([[[ 2.5625, -1.5905,  0.8876,  1.1078,  1.5033],\n",
      "         [-2.0517,  2.8120, -0.6810, -0.6551, -2.7111],\n",
      "         [-2.4725,  1.8294, -0.7338, -0.9053, -0.1320]],\n",
      "\n",
      "        [[-0.4698, -1.8548,  0.6716, -1.1802, -1.9367],\n",
      "         [ 0.5273,  0.8561,  0.8565,  0.6647,  3.9557],\n",
      "         [-2.4954,  1.7016, -0.9597, -1.0404, -1.7845]]])\n",
      "k: tensor([[[ 2.5625, -1.5905,  0.8876,  1.1078,  1.5033],\n",
      "         [-2.0517,  2.8120, -0.6810, -0.6551, -2.7111],\n",
      "         [-2.4725,  1.8294, -0.7338, -0.9053, -0.1320]],\n",
      "\n",
      "        [[-0.4698, -1.8548,  0.6716, -1.1802, -1.9367],\n",
      "         [ 0.5273,  0.8561,  0.8565,  0.6647,  3.9557],\n",
      "         [-2.4954,  1.7016, -0.9597, -1.0404, -1.7845]]])\n",
      "dq torch.Size([2, 3, 3]) tensor([[[ 13.3707, -15.1356, -11.0980],\n",
      "         [-15.1356,  20.3600,  11.6679],\n",
      "         [-11.0980,  11.6679,  10.8354]],\n",
      "\n",
      "        [[  9.2554,  -9.7056,   2.0555],\n",
      "         [ -9.7056,  17.8339,  -8.4316],\n",
      "         [  2.0555,  -8.4316,  14.3104]]])\n"
     ]
    }
   ],
   "source": [
    "def testTransformer():\n",
    "    b, n, d, k = 2, 3, 4, 5\n",
    "    from minGPT.mingpt.utils import set_seed\n",
    "    set_seed(27)\n",
    "    x = torch.normal(0, 1, [b,n,d])\n",
    "    print(\"x:\", x)\n",
    "    x\n",
    "    Q = torch.normal(0, 1, [k,d])\n",
    "    K = torch.normal(0, 1, [k,d])\n",
    "    V = torch.normal(0, 1, [k,d])\n",
    "    # In other words\n",
    "    print(\"Q:\", Q)\n",
    "    res = torch.einsum('kd,bnd->bnk', Q, x)\n",
    "    # Check that it's the same both ways\n",
    "    approx_equals(Q@(x[0,0]), res[0,0])\n",
    "    approx_equals(Q@(x[1,0]), res[1,0])\n",
    "    approx_equals(Q@(x[0,1]), res[0,1])\n",
    "    approx_equals(Q@(x[1,1]), res[1,1])\n",
    "    \n",
    "    q = torch.einsum(\"kd,bnd->bnk\", Q, x)\n",
    "    k = torch.einsum(\"kd,bnd->bnk\", Q, x)\n",
    "    v = torch.einsum(\"kd,bnd->bnk\", Q, x)\n",
    "    \n",
    "    print(\"q:\", q)\n",
    "    print(\"k:\", k)\n",
    "    dotQueryKey = torch.einsum(\"bij, bkj->bik\", q, k)\n",
    "    print(\"dq\", dotQueryKey.shape, dotQueryKey)\n",
    "    \n",
    "    # dotQueryKey[b,i,j] is q[b,i] dot k[b,j]\n",
    "    for ba in range(b):\n",
    "        approx_equals(q[ba,0]@k[ba,0], dotQueryKey[ba,0,0])\n",
    "        approx_equals(q[ba,0]@k[ba,1], dotQueryKey[ba,0,1])\n",
    "        approx_equals(q[ba,1]@k[ba,0], dotQueryKey[ba,1,0])\n",
    "        approx_equals(q[ba,1]@k[ba,1], dotQueryKey[ba,1,1])\n",
    "    \n",
    "testTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[ 1.7650,  0.0664, -0.0706, -0.1672,  0.0756],\n",
      "        [-0.4957, -0.8165, -0.0069, -1.7975, -0.3770],\n",
      "        [ 0.6140,  0.5948, -0.1926,  0.5088,  1.2001],\n",
      "        [ 1.0033,  0.3197, -0.6699,  1.5661,  0.8074]])\n",
      "b tensor([[-1.4775,  0.4753, -0.3383, -0.5367],\n",
      "        [-0.8237, -0.4236,  0.3272, -1.9896],\n",
      "        [-0.9389,  1.5772,  1.6559, -0.4713],\n",
      "        [ 0.2374, -0.1400, -1.0862,  0.5188],\n",
      "        [ 0.6763,  0.1337,  0.0659,  0.5385]])\n",
      "tensor(-2.5848)\n",
      "later stuff\n",
      "tensor(-2.5248)\n",
      "tensor(-0.3093)\n",
      "tensor(1.6219)\n",
      "tensor(1.0495)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5248, -0.3093,  2.8159,  0.9808],\n",
       "        [ 1.6219,  1.0495,  0.2236, -1.1318],\n",
       "        [-1.8210,  1.7328, -0.6841,  1.3748],\n",
       "        [-2.6093,  0.8155,  0.2554,  1.1852]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minGPT.mingpt.utils import set_seed\n",
    "set_seed(27)\n",
    "a = torch.normal(0, 1, [4, 5])\n",
    "b = torch.normal(0, 1, [5, 4])\n",
    "print(\"a\", a)\n",
    "print(\"b\", b)\n",
    "print(a[0]@b[:,0])\n",
    "torch.einsum(\"ij,jk->ik\", a, b)\n",
    "set_seed(27)\n",
    "print(\"later stuff\")\n",
    "a = torch.normal(0, 1, [4, 5])\n",
    "b = torch.normal(0, 1, [4, 5])\n",
    "print(a[0]@b[0])\n",
    "print(a[0]@b[1])\n",
    "print(a[1]@b[0])\n",
    "print(a[1]@b[1])\n",
    "# we want to go from a [nxm],[nxm] to a [n,n]\n",
    "torch.einsum(\"ij,kj->ik\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.7650,  0.0664, -0.0706, -0.1672],\n",
      "         [-0.4266,  1.5005, -0.2636, -1.0210],\n",
      "         [-1.7975, -0.3770,  0.6140,  0.5948]],\n",
      "\n",
      "        [[-0.8629, -0.9511, -0.9195, -0.7592],\n",
      "         [ 0.3197, -0.6699,  1.5661,  0.8074],\n",
      "         [-1.6036,  0.1696, -0.0308,  0.0434]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minGPT.mingpt.utils import set_seed\n",
    "set_seed(27)\n",
    "a = torch.normal(0, 1, [2, 3, 4])\n",
    "print(a)\n",
    "\n",
    "softmax(a)[0,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = LayerNorm(10)\n",
    "inputs = torch.normal(0, 1, [30, 10])\n",
    "ayy = bn(inputs)\n",
    "print(ayy.mean(), ayy.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
